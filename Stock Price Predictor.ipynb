{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *IN PROGRESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, we want to get our stock data. We will be predicting the 'SPY' index ticker using Yahoo Finance as it is the most readily available free source of stock data. \n",
    "\n",
    "    Ideally, we would want to use ticker data in order to create the most optimal model, but that is usually locked behind a broker's database for a fee.\n",
    "\n",
    "Pandas has a neat model called DataReader that makes scraping Stock price points a breeze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas_datareader import data\n",
    "\n",
    "panel_data = data.DataReader('SPY', 'yahoo', '2017-01-01', '2022-06-14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code pulls a DataFrame that can be thought of as a 3D matrix. The first dimension consists of the various fields Yahoo Finance returns for a given instrument, namely, the Open, High, Low, Close and Adj Close prices for each date. The second dimension contain the dates. The third one contains the instrument identifier.\n",
    "    \n",
    "    Google has made fantastic strides in providing us clean data. NaN values from holidays were already accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>225.830002</td>\n",
       "      <td>223.880005</td>\n",
       "      <td>225.039993</td>\n",
       "      <td>225.240005</td>\n",
       "      <td>91366500.0</td>\n",
       "      <td>204.625153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>226.750000</td>\n",
       "      <td>225.610001</td>\n",
       "      <td>225.619995</td>\n",
       "      <td>226.580002</td>\n",
       "      <td>78744400.0</td>\n",
       "      <td>205.842529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>226.580002</td>\n",
       "      <td>225.479996</td>\n",
       "      <td>226.270004</td>\n",
       "      <td>226.399994</td>\n",
       "      <td>78379000.0</td>\n",
       "      <td>205.679031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>227.750000</td>\n",
       "      <td>225.899994</td>\n",
       "      <td>226.529999</td>\n",
       "      <td>227.210007</td>\n",
       "      <td>71559900.0</td>\n",
       "      <td>206.414886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>227.070007</td>\n",
       "      <td>226.419998</td>\n",
       "      <td>226.910004</td>\n",
       "      <td>226.460007</td>\n",
       "      <td>46939700.0</td>\n",
       "      <td>205.733505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10</th>\n",
       "      <td>227.449997</td>\n",
       "      <td>226.009995</td>\n",
       "      <td>226.479996</td>\n",
       "      <td>226.460007</td>\n",
       "      <td>63771900.0</td>\n",
       "      <td>205.733505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-11</th>\n",
       "      <td>227.100006</td>\n",
       "      <td>225.589996</td>\n",
       "      <td>226.360001</td>\n",
       "      <td>227.100006</td>\n",
       "      <td>74650000.0</td>\n",
       "      <td>206.314926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-12</th>\n",
       "      <td>226.750000</td>\n",
       "      <td>224.960007</td>\n",
       "      <td>226.500000</td>\n",
       "      <td>226.529999</td>\n",
       "      <td>72113200.0</td>\n",
       "      <td>205.797104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-13</th>\n",
       "      <td>227.399994</td>\n",
       "      <td>226.690002</td>\n",
       "      <td>226.729996</td>\n",
       "      <td>227.050003</td>\n",
       "      <td>62717900.0</td>\n",
       "      <td>206.269501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-17</th>\n",
       "      <td>226.779999</td>\n",
       "      <td>225.800003</td>\n",
       "      <td>226.309998</td>\n",
       "      <td>226.250000</td>\n",
       "      <td>61240800.0</td>\n",
       "      <td>205.542709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low        Open       Close      Volume  \\\n",
       "Date                                                                     \n",
       "2017-01-03  225.830002  223.880005  225.039993  225.240005  91366500.0   \n",
       "2017-01-04  226.750000  225.610001  225.619995  226.580002  78744400.0   \n",
       "2017-01-05  226.580002  225.479996  226.270004  226.399994  78379000.0   \n",
       "2017-01-06  227.750000  225.899994  226.529999  227.210007  71559900.0   \n",
       "2017-01-09  227.070007  226.419998  226.910004  226.460007  46939700.0   \n",
       "2017-01-10  227.449997  226.009995  226.479996  226.460007  63771900.0   \n",
       "2017-01-11  227.100006  225.589996  226.360001  227.100006  74650000.0   \n",
       "2017-01-12  226.750000  224.960007  226.500000  226.529999  72113200.0   \n",
       "2017-01-13  227.399994  226.690002  226.729996  227.050003  62717900.0   \n",
       "2017-01-17  226.779999  225.800003  226.309998  226.250000  61240800.0   \n",
       "\n",
       "             Adj Close  \n",
       "Date                    \n",
       "2017-01-03  204.625153  \n",
       "2017-01-04  205.842529  \n",
       "2017-01-05  205.679031  \n",
       "2017-01-06  206.414886  \n",
       "2017-01-09  205.733505  \n",
       "2017-01-10  205.733505  \n",
       "2017-01-11  206.314926  \n",
       "2017-01-12  205.797104  \n",
       "2017-01-13  206.269501  \n",
       "2017-01-17  205.542709  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_data.head(10) #Read first 10 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to consider are there any redundant or additional features that we may want to implement into the model. When it comes to trading strategies, there are an abundance of indicators that investors may choose from. \n",
    "\n",
    "One of the most commonly used indicators is the Moving Average (MA) over a set period of time. For example - the 20 day moving average would be referred to as the 20DMA.\n",
    "\n",
    "    Pandas has a built-in rolling() function for Series which returns a rolling object for a user-defined window, e.g. 20 days. We will use the closing prices to calculate the 20DMA, 60DMA and 100DMA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2017-01-03           NaN\n",
      "2017-01-04           NaN\n",
      "2017-01-05           NaN\n",
      "2017-01-06           NaN\n",
      "2017-01-09           NaN\n",
      "                 ...    \n",
      "2022-06-08    403.206001\n",
      "2022-06-09    403.640501\n",
      "2022-06-10    403.513501\n",
      "2022-06-13    402.177501\n",
      "2022-06-14    400.866501\n",
      "Name: Close, Length: 1372, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "spy_close = panel_data['Close']\n",
    "\n",
    "spy_20dma = spy_close.rolling(window=20).mean() # 20 Day Moving Average\n",
    "spy_60dma = spy_close.rolling(window=60).mean() # 60 day\n",
    "spy_100dma = spy_close.rolling(window=100).mean() # 100 day\n",
    "\n",
    "print(spy_20dma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the Series returned from spy_20dma, the first 20 values are expectededly NaN because 20 values are needed to calcultate the 20DMA. Subsequently, I removed the first 100 samples from the data set to make sure every input has values for 20DMA, 60DMA, and 100DMA.\n",
    "\n",
    "Additionally, I feel that the date is valuable for model training, however the object would need to be an integer or float to allow for Python's correct interpretation within machine learning models. Thus, I converted the date values to Unix Epoch by writing the following script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.495685e+09\n",
       "1    1.495771e+09\n",
       "2    1.496117e+09\n",
       "3    1.496203e+09\n",
       "4    1.496290e+09\n",
       "Name: epochDates, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "spyData = pd.read_csv('spyData.csv') # Reading from data that was saved to a csv from panel_data earlier\n",
    "\n",
    "def dateArrange(data):\n",
    "    dates = data['Date'].to_list()\n",
    "    epochDates = []\n",
    "    for i in dates:\n",
    "        splitDate = i.split('/')\n",
    "        newDate = splitDate[2] + ',' + splitDate[0] + ',' + splitDate[1] + ',0,0'\n",
    "        epochDate = datetime(int(splitDate[2]),int(splitDate[0]),int(splitDate[1]),0,0).timestamp()\n",
    "        epochDates.append(epochDate)\n",
    "    data['epochDates'] = epochDates\n",
    "\n",
    "dateArrange(spyData)\n",
    "\n",
    "spyData['epochDates'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
