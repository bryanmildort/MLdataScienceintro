{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# *IN PROGRESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first, we want to get our stock data. We will be predicting the 'SPY' index ticker using Yahoo Finance as it is the most readily available free source of stock data. \n",
    "\n",
    "    Ideally, we would want to use ticker data in order to create the most optimal model, but that is usually locked behind a broker's database for a fee.\n",
    "\n",
    "Pandas has a neat model called DataReader that makes scraping Stock price points a breeze:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from pandas_datareader import data\n",
    "\n",
    "panel_data = data.DataReader('SPY', 'yahoo', '2017-01-01', '2022-06-14')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code pulls a DataFrame that can be thought of as a 3D matrix. The first dimension consists of the various fields Yahoo Finance returns for a given instrument, namely, the Open, High, Low, Close and Adj Close prices for each date. The second dimension contain the dates. The third one contains the instrument identifier.\n",
    "    \n",
    "    Google has made fantastic strides in providing us clean data. NaN values from holidays were already accounted for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2017-01-03</th>\n",
       "      <td>225.830002</td>\n",
       "      <td>223.880005</td>\n",
       "      <td>225.039993</td>\n",
       "      <td>225.240005</td>\n",
       "      <td>91366500.0</td>\n",
       "      <td>204.625153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-04</th>\n",
       "      <td>226.750000</td>\n",
       "      <td>225.610001</td>\n",
       "      <td>225.619995</td>\n",
       "      <td>226.580002</td>\n",
       "      <td>78744400.0</td>\n",
       "      <td>205.842529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-05</th>\n",
       "      <td>226.580002</td>\n",
       "      <td>225.479996</td>\n",
       "      <td>226.270004</td>\n",
       "      <td>226.399994</td>\n",
       "      <td>78379000.0</td>\n",
       "      <td>205.679031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-06</th>\n",
       "      <td>227.750000</td>\n",
       "      <td>225.899994</td>\n",
       "      <td>226.529999</td>\n",
       "      <td>227.210007</td>\n",
       "      <td>71559900.0</td>\n",
       "      <td>206.414886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-09</th>\n",
       "      <td>227.070007</td>\n",
       "      <td>226.419998</td>\n",
       "      <td>226.910004</td>\n",
       "      <td>226.460007</td>\n",
       "      <td>46939700.0</td>\n",
       "      <td>205.733505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-10</th>\n",
       "      <td>227.449997</td>\n",
       "      <td>226.009995</td>\n",
       "      <td>226.479996</td>\n",
       "      <td>226.460007</td>\n",
       "      <td>63771900.0</td>\n",
       "      <td>205.733505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-11</th>\n",
       "      <td>227.100006</td>\n",
       "      <td>225.589996</td>\n",
       "      <td>226.360001</td>\n",
       "      <td>227.100006</td>\n",
       "      <td>74650000.0</td>\n",
       "      <td>206.314926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-12</th>\n",
       "      <td>226.750000</td>\n",
       "      <td>224.960007</td>\n",
       "      <td>226.500000</td>\n",
       "      <td>226.529999</td>\n",
       "      <td>72113200.0</td>\n",
       "      <td>205.797104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-13</th>\n",
       "      <td>227.399994</td>\n",
       "      <td>226.690002</td>\n",
       "      <td>226.729996</td>\n",
       "      <td>227.050003</td>\n",
       "      <td>62717900.0</td>\n",
       "      <td>206.269501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-01-17</th>\n",
       "      <td>226.779999</td>\n",
       "      <td>225.800003</td>\n",
       "      <td>226.309998</td>\n",
       "      <td>226.250000</td>\n",
       "      <td>61240800.0</td>\n",
       "      <td>205.542709</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  High         Low        Open       Close      Volume  \\\n",
       "Date                                                                     \n",
       "2017-01-03  225.830002  223.880005  225.039993  225.240005  91366500.0   \n",
       "2017-01-04  226.750000  225.610001  225.619995  226.580002  78744400.0   \n",
       "2017-01-05  226.580002  225.479996  226.270004  226.399994  78379000.0   \n",
       "2017-01-06  227.750000  225.899994  226.529999  227.210007  71559900.0   \n",
       "2017-01-09  227.070007  226.419998  226.910004  226.460007  46939700.0   \n",
       "2017-01-10  227.449997  226.009995  226.479996  226.460007  63771900.0   \n",
       "2017-01-11  227.100006  225.589996  226.360001  227.100006  74650000.0   \n",
       "2017-01-12  226.750000  224.960007  226.500000  226.529999  72113200.0   \n",
       "2017-01-13  227.399994  226.690002  226.729996  227.050003  62717900.0   \n",
       "2017-01-17  226.779999  225.800003  226.309998  226.250000  61240800.0   \n",
       "\n",
       "             Adj Close  \n",
       "Date                    \n",
       "2017-01-03  204.625153  \n",
       "2017-01-04  205.842529  \n",
       "2017-01-05  205.679031  \n",
       "2017-01-06  206.414886  \n",
       "2017-01-09  205.733505  \n",
       "2017-01-10  205.733505  \n",
       "2017-01-11  206.314926  \n",
       "2017-01-12  205.797104  \n",
       "2017-01-13  206.269501  \n",
       "2017-01-17  205.542709  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panel_data.head(10) #Read first 10 lines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to consider are there any redundant or additional features that we may want to implement into the model. When it comes to trading strategies, there are an abundance of indicators that investors may choose from. \n",
    "\n",
    "One of the most commonly used indicators is the Moving Average (MA) over a set period of time. For example - the 20 day moving average would be referred to as the 20DMA.\n",
    "\n",
    "    Pandas has a built-in rolling() function for Series which returns a rolling object for a user-defined window, e.g. 20 days. We will use the closing prices to calculate the 20DMA, 60DMA and 100DMA:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2017-01-03           NaN\n",
      "2017-01-04           NaN\n",
      "2017-01-05           NaN\n",
      "2017-01-06           NaN\n",
      "2017-01-09           NaN\n",
      "                 ...    \n",
      "2022-06-08    403.206001\n",
      "2022-06-09    403.640501\n",
      "2022-06-10    403.513501\n",
      "2022-06-13    402.177501\n",
      "2022-06-14    400.866501\n",
      "Name: Close, Length: 1372, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "spy_close = panel_data['Close']\n",
    "\n",
    "spy_20dma = spy_close.rolling(window=20).mean() # 20 Day Moving Average\n",
    "spy_60dma = spy_close.rolling(window=60).mean() # 60 day\n",
    "spy_100dma = spy_close.rolling(window=100).mean() # 100 day\n",
    "\n",
    "print(spy_20dma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the Series returned from spy_20dma, the first 20 values are expectededly NaN because 20 values are needed to calcultate the 20DMA. Subsequently, I removed the first 100 samples from the data set to make sure every input has values for 20DMA, 60DMA, and 100DMA.\n",
    "\n",
    "Additionally, I feel that the date is valuable for model training, however the object would need to be an integer or float to allow for Python's correct interpretation within machine learning models. Thus, I converted the date values to Unix Epoch by writing the following script:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.495685e+09\n",
       "1    1.495771e+09\n",
       "2    1.496117e+09\n",
       "3    1.496203e+09\n",
       "4    1.496290e+09\n",
       "Name: epochDates, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "spyData = pd.read_csv('spyData.csv') # Reading from data earlier saved via panel_data.to_csv('spyData.csv')\n",
    "\n",
    "def dateArrange(data):\n",
    "    dates = data['Date'].to_list()\n",
    "    epochDates = []\n",
    "    for i in dates:\n",
    "        splitDate = i.split('/')\n",
    "        newDate = splitDate[2] + ',' + splitDate[0] + ',' + splitDate[1] + ',0,0'\n",
    "        epochDate = datetime(int(splitDate[2]),int(splitDate[0]),int(splitDate[1]),0,0).timestamp()\n",
    "        epochDates.append(epochDate)\n",
    "    data['epochDates'] = epochDates\n",
    "\n",
    "dateArrange(spyData)\n",
    "\n",
    "spyData['epochDates'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After adjusting the data set in Excel (can also easily be done with Pandas commands), the final data set appears as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      epochDates        High         Low        Open       Close     Volume  \\\n",
      "0     1495684800  242.080002  240.960007  241.199997  241.759995   64071700   \n",
      "1     1495771200  241.899994  241.449997  241.539993  241.710007   46629900   \n",
      "2     1496116800  241.789993  241.160004  241.339996  241.500000   35201900   \n",
      "3     1496203200  241.880005  240.639999  241.839996  241.440002   91796000   \n",
      "4     1496289600  243.380005  241.639999  241.970001  243.360001   68962000   \n",
      "...          ...         ...         ...         ...         ...        ...   \n",
      "1271  1655092800  381.809998  373.299988  379.850006  375.000000  170004900   \n",
      "1272  1655179200  377.940002  370.589996  376.850006  373.869995  104011800   \n",
      "1273  1655265600  383.899994  372.119995  377.359985  379.200012  125666800   \n",
      "1274  1655352000  370.940002  364.079987  370.510010  366.649994  134473300   \n",
      "1275  1655438400  369.380005  362.170013  365.510010  365.859985  111071900   \n",
      "\n",
      "       Adj Close       20dma       60dma      100dma  \n",
      "0     220.588715  239.151000  237.026333  234.274200  \n",
      "1     220.543106  239.332501  237.083666  234.438900  \n",
      "2     220.351471  239.473501  237.135000  234.588100  \n",
      "3     220.296753  239.607001  237.197166  234.738500  \n",
      "4     222.048553  239.851001  237.303166  234.900000  \n",
      "...          ...         ...         ...         ...  \n",
      "1271  373.387085  402.177501  423.040001  428.705002  \n",
      "1272  372.261932  400.866501  421.862501  427.976202  \n",
      "1273  377.569031  399.410501  420.776001  427.388402  \n",
      "1274  365.072998  398.150001  419.393668  426.656502  \n",
      "1275  365.859985  396.970001  418.094668  425.970402  \n",
      "\n",
      "[1276 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(spyData)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "369f2c481f4da34e4445cda3fffd2e751bd1c4d706f27375911949ba6bb62e1c"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
